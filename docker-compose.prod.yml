version: "3.9"

# ============================================================
# aitema|Termin - Production Docker Compose
# ============================================================
# Usage:
#   cp .env.example .env && vim .env   # configure secrets
#   docker compose -f docker-compose.prod.yml up -d
# ============================================================

x-common: &common
  restart: unless-stopped
  logging:
    driver: json-file
    options:
      max-size: "50m"
      max-file: "5"

# ============================================================
# Services
# ============================================================
services:

  # ----------------------------------------------------------
  # PostgreSQL 16
  # ----------------------------------------------------------
  postgres:
    <<: *common
    image: postgres:16-alpine
    container_name: termin-postgres-prod
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=de_DE.UTF-8"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
        reservations:
          memory: 512M
    networks:
      - backend
    shm_size: 256mb

  # ----------------------------------------------------------
  # Redis 7 - Session Store & Cache
  # ----------------------------------------------------------
  redis:
    <<: *common
    image: redis:7-alpine
    container_name: termin-redis-prod
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --appendfsync everysec
      --save 900 1
      --save 300 10
      --save 60 10000
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          memory: 128M
    networks:
      - backend

  # ----------------------------------------------------------
  # Keycloak - Identity Provider
  # ----------------------------------------------------------
  keycloak:
    <<: *common
    image: quay.io/keycloak/keycloak:24.0
    container_name: termin-keycloak-prod
    environment:
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://postgres:5432/${POSTGRES_DB}
      KC_DB_USERNAME: ${POSTGRES_USER}
      KC_DB_PASSWORD: ${POSTGRES_PASSWORD}
      KC_DB_SCHEMA: keycloak
      KEYCLOAK_ADMIN: ${KEYCLOAK_ADMIN}
      KEYCLOAK_ADMIN_PASSWORD: ${KEYCLOAK_ADMIN_PASSWORD}
      KC_HOSTNAME: ${KEYCLOAK_HOST}
      KC_PROXY_HEADERS: xforwarded
      KC_HTTP_ENABLED: "true"
      KC_HEALTH_ENABLED: "true"
    command: start --optimized
    depends_on:
      postgres:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G
        reservations:
          memory: 512M
    networks:
      - backend
      - frontend

  # ----------------------------------------------------------
  # Backend (Fastify / Node.js)
  # ----------------------------------------------------------
  backend:
    <<: *common
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: production
    container_name: termin-backend-prod
    environment:
      NODE_ENV: production
      PORT: 3000
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?schema=public
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      KEYCLOAK_URL: http://keycloak:8080
      KEYCLOAK_REALM: ${KEYCLOAK_REALM}
      KEYCLOAK_CLIENT_ID: ${KEYCLOAK_CLIENT_ID}
      KEYCLOAK_CLIENT_SECRET: ${KEYCLOAK_CLIENT_SECRET}
      JWT_SECRET: ${JWT_SECRET}
      SMTP_HOST: ${SMTP_HOST}
      SMTP_PORT: ${SMTP_PORT}
      SMTP_USER: ${SMTP_USER}
      SMTP_PASS: ${SMTP_PASS}
      SMTP_FROM: ${SMTP_FROM}
      CORS_ORIGINS: ${CORS_ORIGINS}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 512M
        reservations:
          memory: 256M
    networks:
      - backend
      - frontend
    volumes:
      - app_logs:/app/logs

  # ----------------------------------------------------------
  # Frontend: BÃ¼rger-Portal (SvelteKit / adapter-node)
  # ----------------------------------------------------------
  frontend-buerger:
    <<: *common
    build:
      context: ./frontend-buerger
      dockerfile: Dockerfile
      target: production
    container_name: termin-buerger-prod
    environment:
      NODE_ENV: production
      ORIGIN: ${BUERGER_ORIGIN}
      BODY_SIZE_LIMIT: "1M"
    depends_on:
      - backend
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
        reservations:
          memory: 128M
    networks:
      - frontend

  # ----------------------------------------------------------
  # Frontend: Mitarbeiter-Portal (SvelteKit / adapter-node)
  # ----------------------------------------------------------
  frontend-mitarbeiter:
    <<: *common
    build:
      context: ./frontend-mitarbeiter
      dockerfile: Dockerfile
      target: production
    container_name: termin-mitarbeiter-prod
    environment:
      NODE_ENV: production
      ORIGIN: ${MITARBEITER_ORIGIN}
      BODY_SIZE_LIMIT: "1M"
    depends_on:
      - backend
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
        reservations:
          memory: 128M
    networks:
      - frontend

  # ----------------------------------------------------------
  # Frontend: Admin-Portal (SvelteKit / adapter-node)
  # ----------------------------------------------------------
  frontend-admin:
    <<: *common
    build:
      context: ./frontend-admin
      dockerfile: Dockerfile
      target: production
    container_name: termin-admin-prod
    environment:
      NODE_ENV: production
      ORIGIN: ${ADMIN_ORIGIN}
      BODY_SIZE_LIMIT: "1M"
    depends_on:
      - backend
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
        reservations:
          memory: 128M
    networks:
      - frontend

  # ----------------------------------------------------------
  # Nginx - Reverse Proxy with TLS
  # ----------------------------------------------------------
  nginx:
    <<: *common
    image: nginx:1.27-alpine
    container_name: termin-nginx-prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - backend
      - frontend-buerger
      - frontend-mitarbeiter
      - frontend-admin
      - keycloak
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 128M
    networks:
      - frontend

# ============================================================
# Volumes
# ============================================================
volumes:
  postgres_data:
    name: termin-postgres-data
  redis_data:
    name: termin-redis-data
  app_logs:
    name: termin-app-logs
  nginx_logs:
    name: termin-nginx-logs

# ============================================================
# Networks
# ============================================================
networks:
  frontend:
    name: termin-frontend
    driver: bridge
  backend:
    name: termin-backend
    driver: bridge
    internal: true
